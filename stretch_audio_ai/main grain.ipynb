{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a3271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" !pip install nbformat tensorflow plotly ipywidgets pyqt5 scipy datasets matplotlib \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48bec04",
   "metadata": {},
   "source": [
    "# Import Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import numpy as np\n",
    "import essentia\n",
    "import essentia.standard as es\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax, Input, InputLayer\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.activations import relu, softmax, sigmoid\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras.metrics import Mean, MeanSquaredError, RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "from tensorflow.keras.metrics import Accuracy, CategoricalAccuracy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "import scipy\n",
    "from scipy.signal import resample\n",
    "\n",
    "from datasets import load_dataset\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d483c",
   "metadata": {},
   "source": [
    "# Check Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad529536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Essentia version:\", essentia.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Plotly version:\", plotly.__version__)\n",
    "print(\"IPyWidgets version:\", widgets.__version__)\n",
    "print(\"SciPy version:\", scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e4ee2",
   "metadata": {},
   "source": [
    "## Definizione variabili globali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = \"dataset/originali\"\n",
    "output_dir = \"dataset/granulati\"\n",
    "sr = 48000\n",
    "window = 1024\n",
    "hop=512\n",
    "default_grain_size=1024\n",
    "default_overlap=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438152dc",
   "metadata": {},
   "source": [
    "#### RIPULISCI DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset directories if they don't exist\n",
    "os.makedirs(original_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directory created/verified:\\n- {original_dir}\\n- {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ff5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Remove all files in output_dir if it exists\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Directory '{output_dir}' has been cleared and recreated\")\n",
    "else:\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Directory '{output_dir}' has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4a577",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0488c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "def clone_audiomnist():\n",
    "    if not os.path.exists('audiomnist'):\n",
    "        print(\"Cloning AudioMNIST repository...\")\n",
    "        os.system('git clone https://github.com/soerenab/AudioMNIST.git audiomnist')\n",
    "        print(\"La repo è stata clonata con successo.\")\n",
    "    else:\n",
    "        print(\"AudioMNIST directory already exists.\")\n",
    "\n",
    "clone_audiomnist() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c446e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def sposta_file_audiomnist():\n",
    "    # Crea la directory di destinazione se non esiste\n",
    "    os.makedirs(original_dir, exist_ok=True)\n",
    "    \n",
    "    # Path alla directory dei dati AudioMNIST\n",
    "    audiomnist_dir = 'audiomnist/audioMNIST/data'\n",
    "    \n",
    "    # Lista per raccogliere tutti i file wav\n",
    "    tutti_i_file = []\n",
    "    \n",
    "    # Attraversa tutte le sottocartelle e raccogli i file\n",
    "    for subdir in os.listdir(audiomnist_dir):\n",
    "        subdir_path = os.path.join(audiomnist_dir, subdir)\n",
    "        \n",
    "        if os.path.isdir(subdir_path):\n",
    "            wav_files = glob(os.path.join(subdir_path, '*.wav'))\n",
    "            tutti_i_file.extend(wav_files)\n",
    "    \n",
    "    # Rinomina e sposta i file\n",
    "    for idx, wav_file in enumerate(tutti_i_file, start=1):\n",
    "        nuovo_nome = f\"{idx}.wav\"\n",
    "        destination = os.path.join(original_dir, nuovo_nome)\n",
    "        \n",
    "        # Copia il file con il nuovo nome\n",
    "        shutil.copy2(wav_file, destination)\n",
    "        print(f\"File {wav_file} spostato come {destination}\")\n",
    "        # Rimuovi il file originale\n",
    "        os.remove(wav_file)\n",
    "        print(f\"File {wav_file} rimosso dopo lo spostamento.\")\n",
    "    \n",
    "    print(f\"\\n Spostati {len(tutti_i_file)} file audio in {original_dir}\")\n",
    "\n",
    "# Esegui la funzione\n",
    "sposta_file_audiomnist() \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NUMBER = 50  # Numero di file da creare\n",
    "\n",
    "def rimuovi_file_extra():\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(original_dir):\n",
    "        print(f\"Directory {original_dir} non esiste.\")\n",
    "        return\n",
    "    \n",
    "    # Get list of wav files\n",
    "    files = glob(os.path.join(original_dir, '*.wav'))\n",
    "    \n",
    "    # Process each file\n",
    "    for file_path in files:\n",
    "        # Extract the number from filename (assuming format like \"301.wav\")\n",
    "        try:\n",
    "            file_number = int(os.path.basename(file_path).split('.')[0])\n",
    "            if file_number > FILE_NUMBER:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Rimosso file: {file_path}\")\n",
    "        except ValueError:\n",
    "            print(f\"Saltato file {file_path}: nome file non valido\")\n",
    "    \n",
    "    # Count remaining files\n",
    "    remaining_files = len(glob(os.path.join(original_dir, '*.wav')))\n",
    "    print(f\"\\nOperazione completata. Rimangono {remaining_files} file in {original_dir}\")\n",
    "\n",
    "# Execute the function\n",
    "rimuovi_file_extra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd263b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b2ef0b7",
   "metadata": {},
   "source": [
    "# Preparazione Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b112bf",
   "metadata": {},
   "source": [
    "## _Carica audio Mono_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af7ef3",
   "metadata": {},
   "source": [
    "test su processo audio trasposto mono "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f39657",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = es.AudioLoader(filename='dataset/originali/1.wav')\n",
    "audio, sr, n_channel, md5, bitrate, codec = loader()\n",
    "audio_T = audio.T[0]\n",
    "audio = audio_T\n",
    "print(audio, sr, n_channel, md5, bitrate, codec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9bcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carica_audio_mono(cartella, max_files=FILE_NUMBER, sr=sr):\n",
    "\n",
    "    filepaths = glob(os.path.join(cartella, '*.wav'))[:max_files]\n",
    "    audio_list = []\n",
    "    for fp in filepaths:\n",
    "        loader = es.AudioLoader(filename=fp)\n",
    "        audio, sr, n_channel, md5, bitrate, codec = loader()\n",
    "        audio_T = audio.T[0]\n",
    "        audio = audio_T\n",
    "        audio_list.append((fp, audio))\n",
    "        # print(f\"Caricato file: {fp}, durata: {len(audio)/sr:.2f} secondi\")\n",
    "    \n",
    "    print(f\"Caricati {len(audio_list)} file audio dalla cartella {cartella}.\")\n",
    "    return audio_list\n",
    "carica_audio_mono(original_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfcb8b",
   "metadata": {},
   "source": [
    "##### _Test function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def carica_audio_mono_e_visualizza(cartella):\n",
    "    filepaths = glob(os.path.join(cartella, '*.wav'))\n",
    "    audio_list = []\n",
    "    \n",
    "    for fp in filepaths:\n",
    "        loader = es.MonoLoader(filename=fp)\n",
    "        audio = loader()\n",
    "        audio_list.append((fp, audio))\n",
    "        print(f\"Caricato file: {fp}, durata: {len(audio)/sr:.2f} secondi\")\n",
    "        \n",
    "        # Visualizza il file audio con IPython.display\n",
    "        display(Audio(data=audio, rate=sr))\n",
    "    \n",
    "    print(f\"Caricati {len(audio_list)} file audio dalla cartella {cartella}.\")\n",
    "    return audio_list\n",
    "carica_audio_mono_e_visualizza(original_dir)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e36a6",
   "metadata": {},
   "source": [
    "## Suddivisione in grani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per suddividere un segnale audio in grani\n",
    "def suddividi_in_grani(audio, grain_size=1024, overlap=512):\n",
    "    step = grain_size - overlap\n",
    "    grains = [audio[i:i+grain_size] for i in range(0, len(audio) - grain_size, step)]\n",
    "    return np.array(grains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637ab56",
   "metadata": {},
   "source": [
    "##### _Test function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd93c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first audio file from the original directory\n",
    "audio_files = carica_audio_mono(original_dir)\n",
    "if audio_files:\n",
    "    filename, audio = audio_files[0]\n",
    "    \n",
    "    # Generate grains using the existing function and global parameters\n",
    "    grains = suddividi_in_grani(audio, grain_size=window, overlap=hop)\n",
    "    \n",
    "    print(f\"Number of grains generated: {len(grains)}\")\n",
    "    print(f\"Each grain size: {window} samples\")\n",
    "    \n",
    "    # Display first 5 grains as audio\n",
    "    print(\"\\nPlaying first 5 grains:\")\n",
    "    for i, grain in enumerate(grains[:5]):\n",
    "        print(f\"\\nGrain {i+1}:\")\n",
    "        display(Audio(data=grain, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b1f160",
   "metadata": {},
   "source": [
    "## Ricombina Grani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ricombina_grani(grani, grain_size, overlap, shuffle=True):\n",
    "    if shuffle:\n",
    "        np.random.shuffle(grani)\n",
    "    output_length = (len(grani) - 1) * (grain_size - overlap) + grain_size\n",
    "    audio_out = np.zeros(output_length)\n",
    "    for i, grain in enumerate(grani):\n",
    "        start = i * (grain_size - overlap)\n",
    "        audio_out[start:start+grain_size] += grain\n",
    "    return audio_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77cd30",
   "metadata": {},
   "source": [
    "##### _Test Function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from IPython.display import Audio, display\n",
    "\n",
    "def visualizza_audio_elaborati(audio_list, sr):\n",
    "\n",
    "    for i, (filename, audio) in enumerate(audio_list):\n",
    "        print(f\"File elaborato {i+1}: {filename}, durata: {len(audio)/sr:.2f} secondi\")\n",
    "        display(Audio(data=audio, rate=sr))\n",
    "\n",
    "# Esempio di utilizzo con file elaborati\n",
    "# Supponiamo di avere una lista di file elaborati\n",
    "audio_elaborati = []\n",
    "\n",
    "# Carica un file audio, suddividilo in grani e ricombinalo\n",
    "audio_files = carica_audio_mono(original_dir)\n",
    "if audio_files:\n",
    "    filename, audio = audio_files[0]\n",
    "    \n",
    "    # Suddividi in grani\n",
    "    grains = suddividi_in_grani(audio, grain_size=window, overlap=hop)\n",
    "    \n",
    "    # Ricombina i grani\n",
    "    audio_ricombinato = ricombina_grani(grains, grain_size=window, overlap=hop, shuffle=True)\n",
    "    \n",
    "    # Aggiungi il file ricombinato alla lista\n",
    "    audio_elaborati.append((f\"Ricombinato_{filename}\", audio_ricombinato))\n",
    "\n",
    "# Visualizza i file elaborati\n",
    "visualizza_audio_elaborati(audio_elaborati, sr) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115967dc",
   "metadata": {},
   "source": [
    "## Salvataggio File Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a91fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salva_audio(audio, path):\n",
    "    writer = es.MonoWriter(filename=path)\n",
    "    writer(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione principale per elaborare tutti i file\n",
    "\n",
    "def elabora_cartella_audio(input_dir='dataset/originali', output_dir='dataset/granulati', grain_size=default_grain_size, overlap=default_overlap):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio_pairs = []\n",
    "    audio_list = carica_audio_mono(input_dir)\n",
    "\n",
    "    for path, audio in audio_list:\n",
    "        grani = suddividi_in_grani(audio, grain_size, overlap)\n",
    "        audio_granulato = ricombina_grani(grani, grain_size, overlap)\n",
    "        nome_file = os.path.basename(path)\n",
    "        output_path = os.path.join(output_dir, 'granulato_' + nome_file)\n",
    "        salva_audio(audio_granulato, output_path)\n",
    "\n",
    "        # Plot\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=audio, mode='lines', name='Originale'))\n",
    "        fig.add_trace(go.Scatter(y=audio_granulato,opacity=0.5, mode='lines', name='Granulato'))\n",
    "        fig.update_layout(title=f'Onda sonora: {nome_file}', xaxis_title='Campione', yaxis_title='Ampiezza')\n",
    "        \n",
    "\n",
    "        audio_pairs.append((audio, audio_granulato))\n",
    "\n",
    "    return audio_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e1c46",
   "metadata": {},
   "source": [
    "Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6090ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elabora_cartella_audio('dataset/originali', 'dataset/granulati', default_grain_size, default_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca9c15",
   "metadata": {},
   "source": [
    "# CARICAMENTO DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715efb86",
   "metadata": {},
   "source": [
    "## Caricamento Dataset e conversione in Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carica_dataset_audio_granulato(originali_dir='dataset/originali', granulati_dir='dataset/granulati'):\n",
    "    X, y = [] , []\n",
    "    for nome_file in os.listdir(originali_dir):\n",
    "        if nome_file.endswith('.wav'):\n",
    "            path_originale = os.path.join(originali_dir, nome_file)\n",
    "            path_granulato = os.path.join(granulati_dir, f'granulato_{nome_file}')\n",
    "\n",
    "            if os.path.exists(path_granulato):\n",
    "                loader = es.MonoLoader(filename=path_originale)\n",
    "                audio_originale = loader()\n",
    "\n",
    "                loader = es.MonoLoader(filename=path_granulato)\n",
    "                audio_granulato = loader()\n",
    "\n",
    "                X.append(audio_granulato)\n",
    "                y.append(audio_originale)\n",
    "\n",
    "    max_len = max(max(len(x), len(t)) for x, t in zip(X, y))\n",
    "\n",
    "    X_padded = np.array([np.pad(x, (0, max_len - len(x)), 'constant') for x in X])\n",
    "    y_padded = np.array([np.pad(t, (0, max_len - len(t)), 'constant') for t in y])\n",
    "\n",
    "    return X_padded, y_padded\n",
    "\n",
    "# Funzione per salvare X e y come file .npz\n",
    "\n",
    "def salva_dataset_npz(X, y, percorso='dataset/dataset.npz'):\n",
    "    np.savez(percorso, X=X, y=y)\n",
    "    print(f\"Dataset salvato in {percorso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131509d",
   "metadata": {},
   "source": [
    "##### _Test Function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ecff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_carica_dataset():\n",
    "    # Load the dataset\n",
    "    X, y = carica_dataset_audio_granulato()\n",
    "    salva_dataset_npz(X, y, 'dataset/dataset.npz')\n",
    "    \n",
    "    print(f\"Dataset loaded: {len(X)} pairs of audio files\")\n",
    "    \n",
    "    # Create visualization for the first few samples\n",
    "    for i in range(min(3, len(X))):\n",
    "        # Create subplot with two traces\n",
    "        fig = make_subplots(rows=2, cols=1, \n",
    "                           subplot_titles=('Audio Granulato (Input)', \n",
    "                                         'Audio Originale (Target)'))\n",
    "        \n",
    "        # Add granulated audio trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=X[i], mode='lines', name='Granulato'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Add original audio trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=y[i], mode='lines', name='Originale'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            title_text=f\"Coppia Audio #{i+1}\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        # Display audio players\n",
    "        print(f\"\\nCoppia Audio #{i+1}\")\n",
    "        print(\"Audio Granulato:\")\n",
    "        display(Audio(data=X[i], rate=sr))\n",
    "        print(\"Audio Originale:\")\n",
    "        display(Audio(data=y[i], rate=sr))\n",
    "test_carica_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e977e2",
   "metadata": {},
   "source": [
    "# Training Macchina e Creazione Modello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68ef8b",
   "metadata": {},
   "source": [
    "##### Modello Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_modello(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dense(input_dim)  # uscita = stessa forma input (regressione)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='mse'\n",
    "        )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bec3c",
   "metadata": {},
   "source": [
    "##### Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungi_rumore(audio, livello_rumore=0.005):\n",
    "    rumore = np.random.normal(0, livello_rumore, audio.shape)\n",
    "    return audio + rumore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a549d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_epoche=100\n",
    "default_batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaff4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addestra_modello(X, y, epoche=50, batch_size=32):\n",
    "    input_dim = X.shape[1]\n",
    "    model = crea_modello(input_dim)\n",
    "\n",
    "    # Augmentazione dati (opzionale)\n",
    "    #X_aug = np.array([aggiungi_rumore(x) for x in X])\n",
    "    #history = model.fit(X_aug, y, epochs=epoche, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "    history = model.fit(X, y, epochs=epoche, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "    print(\"Modello addestrato. Pesi del modello:\")\n",
    "    for layer in model.layers:\n",
    "        pesi = layer.get_weights()\n",
    "        for i, peso in enumerate(pesi):\n",
    "            print(f\"Layer {layer.name} - Peso {i}:\", peso.shape)\n",
    "            print(peso)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Andamento Loss durante il training')\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostra_audio_risultato(model, X, y, indice=0):\n",
    "    #pred = model.predict(np.array([X[indice]]))[0]\n",
    "    prob = Sequential([\n",
    "    model,\n",
    "    Softmax()\n",
    "    #applico softmax per avere le probabilità\n",
    "    ])\n",
    "    predict = prob.predict(np.array([X[indice]]))[0]\n",
    "    print(\"Predizione:\", predict[0])\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(y[indice], label='Originale')\n",
    "    plt.plot(predict, label='Predetto')\n",
    "    plt.legend()\n",
    "    plt.title(\"Audio Originale vs Predetto\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Audio Predetto:\")\n",
    "    display(Audio(predict, rate=sr))\n",
    "\n",
    "    print(\"Audio Originale:\")\n",
    "    display(Audio(y[indice], rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = np.load('dataset/dataset.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "print(\"Dataset shape:\")\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "\n",
    "# Create and train the model\n",
    "input_dim = X.shape[1]\n",
    "model = crea_modello(input_dim)\n",
    "\n",
    "# Data augmentation with noise\n",
    "#X_aug = np.array([aggiungi_rumore(x) for x in X])\n",
    "\n",
    "# Training with validation split\n",
    "history = model.fit(\n",
    "    X, \n",
    "    y, \n",
    "    epochs=default_epoche, \n",
    "    batch_size=default_batch_size, \n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Debug results on first 3 samples\n",
    "print(\"\\nVisualizing results for first 3 samples:\")\n",
    "for i in range(min(3, len(X))):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    mostra_audio_risultato(model, X, y, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Load dataset\n",
    "data = np.load('dataset/dataset.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "print(\"Dataset caricato:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Train model\n",
    "model = addestra_modello(X, y, epoche=default_epoche, batch_size=default_batch_size, salva_pesi=default_model_folder)\n",
    "\n",
    "# Visualize results for first 3 samples\n",
    "for i in range(min(3, len(X))):\n",
    "    print(f\"\\nRisultati per il campione {i+1}:\")\n",
    "    mostra_audio_risultato(model, X, y, i) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45fc7e",
   "metadata": {},
   "source": [
    "# TEST DEGRANULIZER.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predici_audio(model, audio_input):\n",
    "    audio_input = np.array(audio_input)\n",
    "    if len(audio_input.shape) == 1:\n",
    "        audio_input = np.expand_dims(audio_input, axis=0)\n",
    "    return model.predict(audio_input)[0]\n",
    "\n",
    "def visualizza_audio(audio_granulato, audio_rigenerato, audio_originale=None):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=audio_granulato, opacity=0.5, mode='lines', name='Granulato'))\n",
    "    fig.add_trace(go.Scatter(y=audio_rigenerato, mode='lines', name='Rigenerato'))\n",
    "    if audio_originale is not None:\n",
    "        fig.add_trace(go.Scatter(y=audio_originale, opacity=0.5, mode='lines', name='Originale'))\n",
    "    fig.update_layout(title='Confronto Audio', xaxis_title='Campioni', yaxis_title='Ampiezza')\n",
    "    fig.show()\n",
    "\n",
    "def interfaccia_audio(model, X, y=None):\n",
    "    def aggiorna(indice):\n",
    "        audio_granulato = X[indice]\n",
    "        audio_rigenerato = predici_audio(model, audio_granulato)\n",
    "        audio_originale = y[indice] if y is not None else None\n",
    "\n",
    "        visualizza_audio(audio_granulato, audio_rigenerato, audio_originale)\n",
    "\n",
    "        print(\"Audio granulato:\")\n",
    "        display(Audio(audio_granulato, rate=sr))\n",
    "\n",
    "        print(\"Audio rigenerato:\")\n",
    "        display(Audio(audio_rigenerato, rate=sr))\n",
    "\n",
    "        if audio_originale is not None:\n",
    "            print(\"Audio originale:\")\n",
    "            display(Audio(audio_originale, rate=sr))\n",
    "\n",
    "    slider = widgets.IntSlider(min=0, max=len(X)-1, step=1, description='Esempio')\n",
    "    widgets.interact(aggiorna, indice=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaccia_audio(model, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stretch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
